# AI-801-PennState-CourseWork
Repository for AI-801 coursework at Penn State, including assignments, projects, and research in artificial intelligence.
Overview
This repository contains the coursework, projects, and research for AI-801: Artificial Intelligence at Penn State University. The focus of this course is to explore key concepts in artificial intelligence, including machine learning, deep learning, neural networks, and AI algorithms.

Contents
Assignments: Completed coursework and problem sets from AI-801.
Projects: Full AI projects developed as part of the class, including implementation details and results.
Research: Research papers, articles, and experimental results related to AI topics discussed in the course.
Resources: Useful references, datasets, and tools for AI development.
Projects
AI-Powered Tic-Tac-Toe: Game Strategies!


Description: 
Contains the code, data, and research for an AI project that develops an intelligent agent to play an expanded version of Tic-Tac-Toe on a 5x5 grid. Leveraging various AI techniques, including reinforcement learning and Q-Learning, the project explores the challenges of strategic adaptability, performance optimization, and learning from past games.

Key Features:
5x5 Tic-Tac-Toe AI: An AI agent capable of learning and optimizing its gameplay in a more complex Tic-Tac-Toe environment.
Q-Learning Implementation: Utilizes reinforcement learning to improve decision-making and strategy over time.

Technologies Used: Python, Q-Learning, PyTorch).
Outcome: 

AI Performance:

Achieved an 80% win rate after training, with Q-values stabilizing to optimal strategies.
Exploration vs. Exploitation:

Win rate improved from 50% to 80% as the AI shifted from random exploration to learned strategies.
Key Insights:

High mean Q-values indicated preferred actions; low standard deviation showed consistent strategic moves.
Challenges Overcome:

Optimized the Q-Learning agent for performance and adaptability to various strategies.
Limitations & Future Work:

Limitations in scaling to larger environments. Future improvements could explore Deep Q-Learning and dynamic environments.










